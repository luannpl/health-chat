// Importando do pacote correto
import { searchHealthSources, HealthSource } from "@/lib/searchHealthSources";
import { GoogleGenerativeAI, Content } from "@google/generative-ai"; // Importe 'Content'
import { NextResponse } from "next/server";

// InstanciaÃ§Ã£o correta
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

// [MUDANÃ‡A] O System Prompt nÃ£o precisa mais estar no prompt de texto.
// Ele serÃ¡ injetado diretamente no modelo.
const SYSTEM_PROMPT = `VocÃª Ã© um assistente virtual especializado em saÃºde e bem-estar, com conhecimento em:

- NutriÃ§Ã£o e alimentaÃ§Ã£o saudÃ¡vel
- ExercÃ­cios fÃ­sicos, fitness e hipertrofia
- SaÃºde mental e emocional
- Qualidade do sono e rotinas
- PrevenÃ§Ã£o de doenÃ§as e hÃ¡bitos saudÃ¡veis
- Mindfulness e tÃ©cnicas de relaxamento
- GestÃ£o de estresse e ansiedade

DIRETRIZES IMPORTANTES:

1. SEMPRE enfatize que suas orientaÃ§Ãµes sÃ£o informativas e educacionais, NÃƒO substituem consulta mÃ©dica ou de um profissional de educaÃ§Ã£o fÃ­sica.
2. Para sintomas graves ou emergÃªncias, SEMPRE recomende buscar um profissional de saÃºde.
3. Baseie suas respostas em evidÃªncias cientÃ­ficas e prÃ¡ticas reconhecidas.
4. Seja empÃ¡tico, acolhedor e motivador.

5. SEJA ESPECÃFICO E PRÃTICO: Quando o usuÃ¡rio pedir exemplos (como exercÃ­cios, receitas ou tÃ©cnicas), **forneÃ§a exemplos concretos** (ex: "ElevaÃ§Ã£o Lateral", "Arnold Press", "Agachamento") em vez de apenas conselhos genÃ©ricos (ex: "use pesos"). Sempre enquadre-os como sugestÃµes educacionais.

6. Promova uma abordagem holÃ­stica: corpo, mente e bem-estar emocional.

7. Nunca prescreva medicamentos. Ao sugerir rotinas de exercÃ­cios, exemplos de alimentos ou planos de dieta, trate-os como **exemplos educacionais e sugestÃµes informativas**, nÃ£o como prescriÃ§Ãµes mÃ©dicas ou planos de treino individualizados.

8. Incentive hÃ¡bitos sustentÃ¡veis e mudanÃ§as graduais.

9. ESTRUTURA DA RESPOSTA (EM DUAS PARTES):
   - **Bloco Principal:** Use seu **conhecimento interno** para dar a resposta mais direta, especÃ­fica e prÃ¡tica. **Sempre que possÃ­vel**, ENRIQUEÃ‡A e JUSTIFQUE sua resposta usando informaÃ§Ãµes das fontes de contexto fornecidas. Cite as fontes \`[Fonte X]\` apenas quando usar uma informaÃ§Ã£o diretamente delas.
   - **ParÃ¡grafo Final (Separado):** Em um novo parÃ¡grafo, adicione os contrapontos, riscos, e o **aviso legal obrigatÃ³rio** de que suas informaÃ§Ãµes nÃ£o substituem uma consulta profissional.

LIMITAÃ‡Ã•ES DE ESCOPO - MUITO IMPORTANTE:

- VocÃª DEVE responder APENAS perguntas relacionadas a saÃºde e bem-estar.
- Se a pergunta for sobre outros temas (programaÃ§Ã£o, histÃ³ria, matemÃ¡tica, etc.), educadamente decline e redirecione para sua Ã¡rea de especializaÃ§Ã£o.

ESTILO DE COMUNICAÃ‡ÃƒO:

- Use linguagem clara, acessÃ­vel e livre de jargÃµes complexos.
- Seja positivo e encorajador.
- ForneÃ§a dicas prÃ¡ticas e aplicÃ¡veis ao dia a dia.

FORMATO DE RESPOSTA OBRIGATÃ“RIO:

- Responda APENAS com o texto da resposta (string pura), sem nenhum JSON.
- A resposta deve ser completa, empÃ¡tica e estruturada em dois blocos de texto separados por uma quebra de linha.
- **NÃƒO use tÃ­tulos** como "Resposta Principal" ou "Pontos de AtenÃ§Ã£o".
- **NÃƒO use negrito** para os tÃ­tulos (o negrito pode ser usado no corpo do texto para Ãªnfase).
- O primeiro bloco DEVE conter as citaÃ§Ãµes \`[Fonte X]\` (quando as fontes forem usadas para enriquecer).
- O segundo bloco (contrapontos e aviso) NÃƒO deve conter citaÃ§Ãµes \`[Fonte X]\`.
`;

// Interface para o histÃ³rico que esperamos receber do cliente
interface HistoryItem {
  role: "user" | "model";
  message: string;
}

export async function POST(req: Request) {
  console.log("ðŸŸ¢ [API] RequisiÃ§Ã£o recebida no endpoint /api/chat");

  try {
    const body = await req.json();
    // [MUDANÃ‡A] Recebemos 'message' e 'history' do body
    const { message, history } = body as { message: string, history: HistoryItem[] };

    console.log(`ðŸ“¨ Mensagem recebida: "${message}"`);
    console.log(`â³ HistÃ³rico recebido: ${history?.length || 0} turnos`);

    if (!message) {
      console.warn("âš ï¸ Nenhuma mensagem foi fornecida.");
      return NextResponse.json({ error: "Message is required" }, { status: 400 });
    }

    // --- Etapa 1: Sugerir Fontes (DomÃ­nios) ---
    // O RAG (busca de fontes) serÃ¡ baseado APENAS na Ãºltima pergunta do usuÃ¡rio,
    // o que Ã© geralmente mais eficiente.
    const extractionModel = genAI.getGenerativeModel({
      model: "gemini-2.5-flash",
      generationConfig: {
        responseMimeType: "text/plain",
        temperature: 0.0,
      },
    });

    console.log("ðŸ§  [Etapa 1] Solicitando domÃ­nios de fontes ao Gemini...");
    const promptSources = `Com base NESTA PERGUNTA de saÃºde: "${message}", sugira 8-10 domÃ­nios de sites de saÃºde E FITNESS altamente confiÃ¡veis.
    - Se a pergunta for sobre **exercÃ­cio, musculaÃ§Ã£o ou fitness**, inclua domÃ­nios como (ex: treinomestre.com.br, hipertrofia.org, exrx.net, bodybuilding.com, tuasaude.com).
    - Se a pergunta for sobre **saÃºde geral ou medicina**, inclua domÃ­nios como (ex: mayoclinic.org, who.int, cdc.gov, tuasaude.com, mdsaude.com, drauziovarella.uol.com.br).
    Responda APENAS com os domÃ­nios, separados por vÃ­rgula.`;

    const sourcesResult = await extractionModel.generateContent({
      contents: [{ role: "user", parts: [{ text: promptSources }] }],
    });
    const domainsString = sourcesResult.response.text().trim();
    console.log(`ðŸŒ DomÃ­nios sugeridos pela LLM: ${domainsString}`);

    // --- Etapa 2: Montar a Query de Busca (RAG) ---
    console.log("ðŸ§  [Etapa 2] Montando query de busca...");
    const domains = domainsString.split(',').map(d => d.trim()).filter(d => d.length > 0);
    
    let finalSearchQuery = message; 
    if (domains.length > 0) {
      const siteQuery = domains.map(d => `site:${d}`).join(' OR ');
      finalSearchQuery = `${message} (${siteQuery})`; 
    }
    console.log(`ðŸ” Query final para busca (RAG): ${finalSearchQuery}`);

    // --- Etapa 3: Buscar fontes (RAG) ---
    console.log("ðŸŒ [Etapa 3] Iniciando busca online de fontes (RAG)...");
    const sourcesArray: HealthSource[] = await searchHealthSources(finalSearchQuery);
    console.log("âœ… Busca concluÃ­da. Fontes estruturadas recebidas.");

    // --- Etapa 4: Preparar dados para o prompt final ---
    const contextString = sourcesArray
      .map(
        (s, i) =>
          `[Fonte ${i + 1}]\nTÃ­tulo: ${s.title}\nConteÃºdo: ${s.snippet}\nLink: ${s.link}`
      )
      .join("\n\n");
    const linksArray = sourcesArray.map((s) => s.link);

    // --- Etapa 5: Montar o prompt aumentado final ---
    
    // [MUDANÃ‡A] Formatamos o histÃ³rico recebido para o formato do Gemini
    const formattedHistory: Content[] = (history || []).map(item => ({
      role: item.role,
      parts: [{ text: item.message }]
    }));

    // [MUDANÃ‡A] A nova mensagem do usuÃ¡rio Ã© formatada com o contexto RAG
    // O SYSTEM_PROMPT nÃ£o estÃ¡ mais aqui, ele vai na configuraÃ§Ã£o do modelo.
    const finalUserMessage = `
    Fontes confiÃ¡veis encontradas na web (use-as para enriquecer o primeiro bloco de texto, se relevante):
    ---
    ${contextString.length > 0 ? contextString : "Nenhuma fonte encontrada."}
    ---

    INSTRUÃ‡Ã•ES IMPORTANTES:
    1. Siga **exatamente** o FORMATO DE RESPOSTA OBRIGATÃ“RIO (definido nas instruÃ§Ãµes do sistema).
    2. Gere o **primeiro bloco de texto** usando seu conhecimento interno e as fontes (citando-as).
    3. Gere o **parÃ¡grafo final (separado)** com o aviso legal.

    Pergunta do usuÃ¡rio:
    ${message}
    `;

    // --- Etapa 6: Gerar a Resposta Final (LLM Call 2) ---
    console.log("ðŸ§  [Etapa 6] Enviando prompt e histÃ³rico para o Gemini...");
    
    // [MUDANÃ‡A] O System Prompt Ã© passado aqui, na 'systemInstruction'
    const answerModel = genAI.getGenerativeModel({
      model: "gemini-2.5-flash",
      systemInstruction: SYSTEM_PROMPT, // <-- AQUI
      generationConfig: {
        responseMimeType: "text/plain",
        temperature: 0.2, 
      },
    });

    // [MUDANÃ‡A] Montamos o array de 'contents' com o histÃ³rico + nova mensagem
    const contents: Content[] = [
      ...formattedHistory,
      { role: 'user', parts: [{ text: finalUserMessage }] }
    ];

    const result = await answerModel.generateContent({
      contents: contents, // <-- Passa o histÃ³rico completo
    });

    const response = result.response;
    const modelAnswer = response.text();
    console.log("ðŸ“© Resposta (texto puro) recebida do Gemini");

    // --- Etapa 7: Montar o JSON final ---
    const jsonData = {
      answer: modelAnswer.trim(),
      sources: linksArray,
    };

    console.log("âœ… JSON final montado manualmente");

    return NextResponse.json(jsonData);
  } catch (error) {
    console.error("ðŸš¨ Erro geral no processamento da rota /api/chat:", error);
    return NextResponse.json(
      {
        answer: "Ocorreu um erro interno ao processar sua solicitaÃ§Ã£o.",
        sources: [],
      },
      { status: 500 }
    );
  }
}